# 第一章 可靠、可扩展与可维护的应用系统

## 数据密集型应用模块

1. **数据库：**用以存储数据，这样之后应用可以再次访问。
2. **高速缓存：**缓存那些复杂或操作代价昂贵的结果，以加快下一次访问。 
3. **索引：**用户可以按关键字搜索数据井支持各种过滤。
4. **流式处理：**持续发送消息至另一个进程，处理采用异步方式。 
5. **批处理：**定期处理大量的累积数据。
<br>

## 软件系统三大重要性质

1. **可靠性Reliability：**当出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转，虽然性能可能有所降低，但确保功能正确。
2. **可扩展性Scalability：**随着规模增长 ，例如数据量、流量或复杂性，系统应以合理的方式来匹配这种增长。
3. **可维护性Maintainability：**随着时间的推移，许多新的人员参与到系统开发和运维，以维护现有功能或适配新场景等，系统都应高效运转。
<br>

## 实现可靠性

> **硬件故障**

1. **采用硬件冗余方案对于大多数应用场景是足够的**，它使得单台机器完全失效的概率降为非常低的水平。只要可以将备份迅速恢复到新机器上，故障的停机时间在大多数应用中并不是灾难性的。而多机冗余则只对少量的关键应用更有意义，对于这些应用，高可用性是必要的。
2. 随着数据量和应用计算需求的增加，更多的应用可以运行在大规模机器上，随之而来的硬件故障率呈线性增长。因此**通过软件容错的方式来容忍多机失效成为新的手段，或者至少成为硬件容错的有力补充**。系统更具有操作便利性，如重启计算机时为操作系统打安全补丁，可以每次给一个节点打补丁然后重启，而不需要同时下线整个系统，即滚动升级。

> **软件错误**

1. 通常认为硬件故障之间是相互独立的，不会出现大量硬件组件同时失效。**软件故障事先更加难以预料，节点之间是由软件关联的，往往会导致更多的系统故障**。
2. 软件系统问题没有快速解决办法，只能仔细考虑细节问题，包括认真检查依赖的假设条件与系统之间交互，**进行全面的测试**，**进程隔离**，**允许进程崩溃并自动重启**，反复评估，监控并分析生产环节的行为表现等。

> **人为错误**

1. **以最小出错的方式来设计系统**，**想办法分离最容易出错的地方、容易引发故障的接口**。特别是提供一个功能齐全但非生产用的沙箱环境，使人们可以放心的尝试、体验。
2. **充分的测试**；当出现人为失误时，**提供快速的恢复机制以尽量减少故障影响**；**设置详细而清晰的监控子系统**，包括性能指标和错误率。
<br>


## 实现可扩展性

0. **可扩展性是用来描述系统应对负载增加能力的术语**。
> **描述负载**

1. 负载参数最佳选择取决于系统的体系结构，如Web服务器的每秒请求处理次数，数据库中写入的比例，聊天室的同时活动用户数量， 缓存命中率等。 **有时平均值很重要，有时系统瓶颈来自于少数峰值。**

> **描述性能**

1. 在批处理系统如Hadoop中通常关心**吞吐量**，即每秒可处理的记录条数，或者在某指定数据集上运行作业所需的总时间；而在线系统通常更看重**服务的响应时间**，即客户端从发送请求到接收响应之间的间隔。
4. 想知道更典型的响应时间，平均值并不是合适的指标，它无法告诉有多少用户实际经历了多少延迟，最好使用**百分位数**。**中位数指标非常适合描述多少用户需要等待多长时间**，一半的用户请求的服务时间多于中位数响应时间。也称为50百分位数p50。为了弄清楚**异常值有多糟糕**，需要关注更大的百分位数如常见的p95、p99和p999值。

>  **应对负载增加**

1. 现在谈论更多的是如何在**垂直扩展 (即升级到更强大的机器)和水平扩展 (即将负载分布到多个更小的机器)**之间做取舍。在多台机器上分配负载也被称为**无共享体系结构**。
2. 相比无状态服务，有状态服务扩展到分布式多机环境的复杂性会大大增加。出于这个原因，通常是将数据库运行在一个节点上，采用垂直扩展策略，直到高扩展性或高可用性的要求不得不做水平扩展。
3. 超大规模的系统往往针对特定应用而高度定制，很难有通用的架构。取舍因素包括数据读取量、写入量、待存储的数据量、数据的复杂程度、响应时间要求、访问模式等。即使数据吞吐量相同，为每秒处理10w次1KB请求而设计的系统，与为每分钟3个2GB请求设计的系统也大不相同。
<br>

## 实现可维护性

> **可运维性**

1. 提供对系统运行时行为和内部的可观测性，方便监控；支持自动化，与标准工具集成。
2. 避免绑定特定机器，允许机器停机维护；提供良好的文档和易于理解的操作模式。
3. 提供良好的默认配置，允许简单操作修改默认值。
4. 尝试自我修复，可在需要时让管理员手动控制系统状态；行为可预测，减少意外发生。

> **简单性**

1. 简化系统设计并不意味着减少系统功能，而主要意味着消除意外方面的复杂性，即并非软件固有、被用户所见或感知，而是实现本身所衍生出来的问题。
2. **消除意外复杂性最好手段之一是抽象**，一个好的设计抽象可以隐藏大量的实现细节，并对外提供干净、易懂的接口，可复用于各种不同的应用程序。

> **可演化性——易于改变**

1. 在组织流程方面 ，**敏捷开发模式为适应变化提供了很好的参考**。敏捷社区还发布很多技术工具和模式，以帮助在频繁变化的环境中开发软件，例如测试驱动开发TDD和重构。
<br>
# 第二章 数据模型与查询语言

## NoSQL的优点

1. 比关系数据库更好的扩展性需求，包括支持超大数据集或超高写入吞吐量。
2. 免费的开源软件，而不是商业数据库产品。
3. 关系模型不能很好地支持一些特定的查询操作，渴望更具动态和表达力的数据模型。
<br>

## 对象与关系模型的不匹配

1. 如果数据存储在关系表中，那么**应用层代码中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层**。模型之间的脱离有时被称为**阻抗失谐**。ActiveRecord和Hibernate这样的对象-关系映射(ORM)框架减少了此转换层所需的样板代码量，但是并不能完全隐藏两个模型之间的差异。
2. 对于具备**一对多**关系的数据，常见的模型是将信息放在单独表中，用外键关联；或者用JSON文档模型来表示整个数据。**JSON表示比多表模式具有更好的局部性**。在关系模式中读取完整数据要执行多次查询或关联多个表。而JSON表示方法只需要一次查询。
3. 对于具备**多对一**关系的数据，如果“一”端数据经常需要修改，则使用外键进行关联较为简单，使用文档数据模型则产生冗余的修改操作。**当需要表达多对多关系时，并不是很适合文档模型**。关系数据库由于支持联结操作，可以很方便地通过ID来引用其他表中的行。而在文档数据库中， 一对多的树状结构不需要联结，支持联结通常也很弱。
4. 如果数据库本身不支持联结，则必须在应用程序代码中，通过对数据库进行多次查询来模拟联结。**即使应用程序的初始版本非常适合采用无联结的文档模型，但随着应用支持越来越多的功能，数据也变得更加互联一体化。**
<br>

## 层次模型与网络模型

1. 层次模型与文档数据库使用的JSON模型有一些显著的相似之处，它将所有数据表示为嵌套在记录中的记录(树)。可以很好地支持一对多关系中，但支持多对多关系则有些困难，而且不支持联结。
2. 网络模型是层次模型的推广。在层次模型的树结构中，每个记录只有一个父结点；而在网络模型中，一个记录可能有多个父结点，从而支持对多对一和多对多的关系进行建模。记录之间的链接不是外键，而更像是指针。访问记录的唯一方法是选择一条始于根记录的路径，并沿着相关链接依次访问。
3. 尽管手动路径选择能够最有效地利用有限的硬件资源，但最大的问题在于查询和更新数据库变得异常复杂而没有灵活性。无论是层次模型还是网络模型，如果脱离数据的访问路径那么将寸步难行。
4. **关系模型则没有复杂的嵌套结构和访问路径**，查询优化器自动决定选择什么顺序和索引，相当于访问路径，但由查询优化器自动生成，只需构建一次查询优化器，后续所有使用数据库的应用程序都将收益，避免了手动编写访问路径。
<br>

## 关系型数据库和文档型数据库的比较

1. 从以下角度来看，文档数据库是某种方式的层次模型：即在其父记录中保存了嵌套记录(一对多关系) ，而不是存储在单独的表中。
2. 在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同，**相关项都由唯一的标识符引用**，该标识符在关系模型中被称为**外键**，在文档模型中被称为**文档引用**。标识符可以在查询时通过联结操作或相关后续查询来解析。
3. **文档数据模型有较好灵活性，由于局部性而带来较好的性能 ，对于某些应用来说更接近于应用程序所使用的数据结构。关系模型强在联结操作、多对一和多对多关系更简洁的表达上，与文档模型抗衡。**
<br>
## 文档模型中的模型灵活性和查询局部性

1. 大多数文档数据库，以及关系数据库中的JSON支持，都不会对文档中的数据强制执行任何模式。如果集合中的项由于某种原因并**不都具有相同的结构**，模式带来的损害大于它所能提供的帮助，**无模式文档可能是更自然的数据模型**。当所有记录都有相同结构时，模式则是记录和确保这种结构的有效机制。
2. **如果应用程序需要频繁访问整个文档，存储局部性具有性能优势。如果数据被划分在多个表中，则需要进行多次索引查找来检索所有数据，中间可能需要更多的磁盘I/O井花费更多的时间。**
3. **局部性优势仅适用需要同时访问文档大部分内容的场景**。由于数据库通常会加载整个文档，如果应用只是访问其中的小部分，则对于大型文档数据来讲会造成浪费。对文档进行更新时，通常会重写整个文档，而只有修改量不改变文档大小时， 原地覆盖更新才更有效。**因此，通常建议文档应该小且避免写入时增加文档大小，这些性能方面的不利因素大大限制了文档数据库的适用场景。**
<br>

## 图状数据模型

1. 关系模型能够处理简单的多对多关系， 但是随着数据之间的关联越来越复杂，将数据建模转化为图模型会更加自然。图的顶点可以表示相同类型的事物，**也可以保存完全不同类型对象**。
2. 可以将图存储看作由两个关系表组成，一个用于顶点， 另一个用于边。给定某个顶点，可以高效地得到它的所有入边和出边，从而遍历图。
3. 在关系数据库中，通常会预先知道查询中需要哪些join操作。而对于图查询，在找到要找的顶点之前，可能需要遍历数量未知的边即join操作数量并不是预先确定的。如查询所有出生于美国(顶点)的人(顶点)。
<br>
## 数据模型总结

1. 历史上，数据最初被表示为一棵大树即层次模型，但是这不利于表示多对多关系，所以发明了关系模型。而有些应用程序也不太适合关系模型，即出现新的非关系NoSQL数据模型。
	* 文档数据库的目标用例是数据来自于自包含文挡，且文档之间的关联很少。
	* 图数据库则针对相反的场景，目标用例是所有数据都可能会互相关联。
2. 文档数据库和图数据库有个共同点，那就是它们通常不会对存储的数据强加某个模式，这可以使应用程序更容易适应不断变化的需求。但是，应用程序很可能仍然假定数据具有一定的结构，只不过是模式是显式（写时强制）还是隐式（读时处理）的问题。
<br>

# 第三章 数据存储与检索

## 数据库核心——数据结构

1. 许多数据库内部都使用日志来存储数据，日志是一个仅支持追加式更新的数据文件。从头到尾扫描整个数据库文件来查找键的出现位置，开销是O(n)，为了高效地查找数据库中特定键，引入需要新的数据结构，即索引。
<br>

## 哈希索引——传统内存中索引

> **数据结构设计**

1. 假设数据存储全部采用追加式文件组成，那么最简单的索引策略就是保存内存中的hashMap，把每个键一一映射到数据文件中特定的字节偏移，这样就可以找到每个值的位置。
2. 只要**所有的key可以放入内存**(因为hashMap需要保存在内存中)。而value数据量则可以超过内存大小，只需一次磁盘寻址，就可以将value从磁盘加载到内存。如果那部分数据文件已经在文件系统的缓存中，则读取根本不需要任何的磁盘I/O。就可以提供高性能的读和写，非常适合每个键的值频繁更新的场景。

> **如何避免日志文件最终用尽磁盘空间**

1. 一个好的解决方案是将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中。并且可以在这些段上执行压缩，在日志中只保留每个键最近的更新。
2. 由于压缩往往使得段更小，也可以在执行压缩的同时将多个段合并在一起。由于段在写入后不会再进行修改，合并的段会被写入另一个新的文件。对于这些冻结段的合并和压缩过程可以在后台线程中完成，运行时仍然可以用旧的段文件继续正常读取和写请求。当合并过程完成后，将读取请求切换到合并段上，而旧的段可以安全删除。
3. 每个段现在都有自己的内存哈希，将键映射到文件的偏移量。为了找到键的值，首先检查最新的段的 hashMap；如果键不存在，检查第二最新的段，以此类推。

> **实现细节**

1. **文件格式：**csv不是日志的最佳格式，更快更简单的方法是使用二进制格式。先以字节为单位记录字符串长度，再接上原始字符串。
2. **删除记录：**如果要删除键和关联的值，则必须在数据文件中追加一个特殊的删除记录，称为墓碑。当合并日志段发现墓碑标记时，丢弃这个己删除键的所有值。
3. **崩愤恢复：**如果数据库重新启动，则内存中的hashMap将丢失。通过将每个段的hashMap的快照存储在磁盘上，可以更快地加载到内存中，以此加快恢复速度。
4. **部分写入的记录：**数据库随时可能崩愤，包括将记录追加到日志的过程中，进行文件校验，可以发现损坏部分井丢弃。
5. **并发控制：**由于写入以严格的先后顺序追加到日志中，通常的实现选择是只有一个写线程。 数据文件段是追加的，并且是不可变的，所以他们可以被多个线程同时读取。

> **追加的日志浪费空间，为什么不原地更新文件用新值覆盖旧值？**

1. 追加和分段合并主要是**顺序写，比随机写入快得多**。
2. 如果**段文件是追加的或不可变的，则并发和崩愤恢复要简单得多**。不必担心在重写值时发生崩愤情况，留下一个包含部分旧值和部分新值混杂在一起的文件。
3. **合并旧段可以避免随着时间的推移数据文件出现碎片化的问题**。

> **局限性**

1. 哈希表必须全部放入内存，如果有大量的键，即使可以在磁盘上维护hashMap，也很难使磁盘上的ha shMap表现良好。需要大量的随机访问I/O，当哈希变满时，继续增长代价昂贵，井且哈希冲突时需要复杂的处理逻辑。
2. 区间查询效率不高。
<br>

## SSTables——日志段格式改变

0. 改变哈希日志段文件的格式，要求**对key-value的顺序按键排序**。这种格式称为**排序字符串表SSTable**。要求**每个键在每个合并的段文件中只能出现一次**(压缩过程已经确保了)。**索引还是在内存中**。

> **相比哈希日志段的优点**

1. **合并段更加简单高效**，即使文件大于可用内存。类似于合并排序算法。当多个段包含相同的键时，可以保留最新段的值并丢弃旧段中的值。
2. **在文件中查找特定的键时，不再需要在内存中保存所有键的索引**。需要一个内存索引来记录某些键的偏移，但它可以是稀疏的，可以按照键的顺序确定某个键在哪两个索引之间(类似二分查找)。由于可以很快扫描几千字节，对于段文件内每几千字节，只需要一个键就足够了。

> **如何让数据按键排序？**

1. 在磁盘上维护排序结构是可行的，但将其保存在内存中更容易。内存排序可以使用很多树状数据结构如红黑树或AVL树，可以按任意顺序插入键并以排序后的顺序读取。
2. 当**写入时将其添加到内存中的树数据结构中**；当内存表大于某个阈值时，将其作为SSTables文件写入磁 盘。由于树已经维护了按键排序的key-value对，磁盘可以比较高效。新的SSTable文件成为数据库的最新部分。写磁盘的同时，新的写入可以继续添加到新的内存表实例中。
3. 为了处理读请求，首先尝试在内存表中查找键，然后是最新的磁盘段文件，接下来是次新，以此类推直到找到目标或为空。后台进程周期性地执行段合并与压缩过程，以合并多个段文件。

> **问题与方案**

1. 如果数据库崩愤，在内存表中尚未写入磁盘的数据将丢失。为了避免该问题，可以在磁盘上保留单独的日志，每个写入都会立即追加到该日志，该日志文件不需要按键排序，唯一目的是在崩愤后恢复内存表。每当将内存表写入SSTable时，相应的日志可以被丢弃。
<br>

## 从SSTables到LSM-Tree

1. **具备SSTables日志段格式的索引结构称为以日志结构的合并树即LSM-Tree**。基于合井和压缩排序文件原理的存储引擎通常都被称为LSM存储引擎。即使数据集远大于可用内存，它仍然能够正常工作，由于数据按排序存储，因此可以有效地执行查询，从最小值到最大值扫描所有的键，并且由于磁盘是顺序写入的，LSM-tree可以支持非常高的写入吞吐量。
2. Lucene是ElasticSearch和Solr等全文搜索系统所使用的索引引擎，它主要采用key-value结构实现，其中键是单词即词条，值是所有包含该单词的文档ID的列表即倒排表。在Lucene中，从词条到posting list的映射关系保存在类SSTable的排序文件中，这些文件可以根据需要在后台合并。为了处理文档或查询中的拼写错误， Lucene能够在某个编辑距离内搜索文本，即支持模糊索引。

> **性能优化**

1. 当查找数据库中某个不存在的键时，LSM-Tree算法在确定键不存在之前，必须先检查内存表，然后将段一直回溯访问到最旧的段文件，可能必须从磁盘多次读取。为了优化这种访问，存储引擎通常使用额外的**布隆过滤器**。
2. 不同的策略会影响甚至决定SSTables压缩和合并时的具体顺序和时机 。最常见的方式是大小分级和分层压缩。在大小分级的压缩中，较新的和较小的SSTables被连续合并到较旧和较大的SSTables。在分层压 缩中，键的范围分裂成多个更小的SSTable，旧数据被移动到单独的层级，这样压缩可以逐步进行并节省磁盘空间。
<br>

## B-Tree

1. 像SSTable一样，**B-Tree保留按键排序的key-value对**，这样可以实现高效的key-value查找和区间查询。但是之前的日志结构索引将数据库分解为不定长的段，并且始终按顺序写入段。相比之下，**B-Tree将数据库分解成固定大小的块或页，页是内部读写的最小单元。这种设计更接近底层硬件，因为磁盘也是以固定大小的块排列**。
2. 每个页面都可以使用地址或位置进行标识，这样可以让一个页面引用另一个页面，使用这些页面引用来构造一个树状结构。某一页被指定为B-tree的根，每当查找索引中的一个键时，总是从这里开始。该页面包含若干个键和对子页的引用。每个孩子都负责一个连续范围内的键，相邻引用之间的键可以指示这些范围之间的边界。

> **使B-Tree可靠**

1. B-tree底层的基本写操作是**使用新数据覆盖磁盘上的旧页**。它假设覆盖不会改变页的磁盘存储位置，当页被覆盖时，对该页的所有引用保持不变。**与日志结构索引(如LSM-tree) 形成鲜明对比**，LSM-tree仅追加更新文件(并最终删除过时的文件)，但不会修改文件。
2. 如果插入导致页溢出，需分裂页，那么需要写两个分裂的页，并且覆盖其父页以更新对两个子页的引用。如果数据库在完成部分页写入之后发生崩溃，最终会导致索引破坏。即可能有一个孤儿页，没有被任何其他页所指向。常见B-tree的实现需要重做日志，是一个仅支持追加修改的文件。
3. 如果多个线程要同时访问B-tree，则需要注意并发控制，否则线程可能会看到树处于不一致的状态。通常使用锁存器保护树的数据结构来完成。日志结构化的方法则显得更简单，因为它们在后台执行所有合并，而不会干扰前端的查询，并且会不时地用新段原子地替换旧段。
<br>

## 对比B-Tree和LSM-Tree

0. LSM-tree通常对于写入更快，而B-tree被认为对于读取更快。读取通常在LSM-tree上较慢，因为它们必须在不同的压缩阶段检查多个不同的数据结构和SSTable。

> **LSM-Tree的优点**

1. B-tree索引必须至少写两次数据，一次写入预写日志，一次写入树的页本身，还可能发生页分裂。由于反复压缩和SSTable的合并，日志结构索引也会重写数据多次。在数据库内由于一次数据库写入请求导致的多次磁盘写称为写放大。
2. LSM-tree通常能够承受比B-tree更高的写入吞吐量，部分是因为它们有时具有较低的写放大，部分原因是它们以顺序方式写入紧凑的SSTable文件，而不必重写树中的多个页。磁盘的顺序写比随机写要快得多。
3. LSM-tree可以支持更好地压缩，因此通常磁盘上的文件比B-tree小很多。由于碎片，B-tree存储引擎使某些磁盘空间无法使用。由于LSM-tree不是面向页的，并且定期重写SSTables以消除碎片化，所以它们具有较低的存储开销，特别是在使用分层压缩时。

> **LSM-tree的缺点**

1. 日志结构存储的缺点是压缩过程有时会干扰正在进行的读写操作。即使存储引擎尝试增量地执行压缩，并且不影响并发访问，但由于磁盘的并发资源有限，所以当磁盘执行昂贵的压缩操作时，很容易发生读写请求等待的情况。
2. 高写入吞吐量时，磁盘的有限写入带宽需要在初始写入和后台运行的压缩线程之间所共享。如果写入吞吐量很高并且压缩没有仔细配置，那么就会发生压缩无法匹配新数据写人速率的情况。在这种情况下，磁盘上未合并段的数量不断增加，直到磁盘空间不足，由于它们需要检查更多的段文件，因此读取速度也会降低。
3. B-tree的优点则是每个键都恰好唯一对应于索引中的某个位置，而日志结构的存储引擎可能在不同的段中具有相同键的多个副本。在许多关系数据库中，事务隔离是通过键范围上的锁来实现的，并且在B-tree索引中，这些锁可以直接定义到树中。
<br>

## 在内存中保存所有内容

1. **内存数据库的性能优势并不是因为它们不需要从磁盘读取**。如果有足够的内存，即使是基于磁盘的存储引擎，也可能永远不需要从磁盘读取，因为操作系统将最近使用的磁盘块缓存在内存中。相反，**内存数据库可以更快，是因为它们避免使用写磁盘的格式对内存数据结构编码的开销**。
2. 内存数据库提供了基于磁盘索引难以实现的某些数据模型。由于所有的数据都保存在内存中，所以实现可以比较简单
3. 内存数据库架构可以扩展到支持远大于可用内存的数据集，而不会导致以磁盘为中心架构的开销。反缓存方法即当没有足够的内存时，通过将最近最少使用的数据从内存写到磁盘，并在将来再次被访问时将其加载到内存。
<br>

## 事务处理与分析处理

1. 应用程序通常使用索引中的某些键查找少量记录，根据用户的输入插入或更新记录，其基本访问模式仍然与处理业务交易类似。因为这些应用程序是交互式的，所以访问模式被称为在线事务处理**OLTP**，online transaction processing。
2. 用于数据分析的数据库具有非常不同的访问模式，分析查询需要扫描大量记录，每个记录只读取少数几列，并计算汇总统计信息，而不是返回原始数据给用户。为了区分使用数据库与事务处理的模式，称之为在线分析处理**OLAP**，online analytic processing。用于分析目的的单独数据库也被称为数据仓库。

<img src="https://gitee.com/jia_hope/markdown-img/raw/master/img/20230301173832.png">
<br>

## 数据仓库

1. OLTP系统对于业务的运行至关重要，往往要求高度可用，处理事务时延迟足够低。通常不愿意让业务分析人员在OLTP数据库上直接运行临时分析查询，这些查询通常代价很高，要扫描大量数据集，这可能会损害并发执行事务的性能。
2. 数据仓库则是单独的数据库，分析人员可以在不影响OLTP操作的情况下尽情地使用。数据仓库包含公司所有各种OLTP系统的只读副本。从OLTP数据库中提取数据，转换为分析友好模式，执行必要的清理，然后加载到数据仓库中。将数据导入数据仓库的过程称为提取-转换-加载，Extract-Transform-Load即ETL。
<br>

## OLAP数据仓库和OLTP数据库的差异

1. 数据仓库的数据模型最常见的是关系型，因为SQL通常适合分析查询。表面上，数据仓库和关系型OLTP数据库看起来相似，但系统统内部差异很大，针对不同的查询模式进行了各自优化。
2. 即使一些数据库在同一产品中支持事务处理和数据仓库。然而，它们越来越成为两个独立的存储和查询引擎，这些引擎恰好可以通过一个通用的SQL界面进行访问。
<br>

## 星型与雪花型分析模式

1. 不同于事务处理领域有多种数据模型，分析型业务的数据库的数据模型则少得多。其中常用的星型模式也称为维度建模，模式的中心是一个事实表，每一行表示特定时间发生的事件，如每一行代表客户购买的一个产品。
2. 通常事实被捕获成单独的事件，之后的分析更具灵活性，但也意味着事实表会非常庞大。事实表中的列是属性，也可能是引用其他表的外键，称为维度表。维度通常代表事件发生的对象、事件、地点、方式等。
3. 雪花模式则将维度进一步细分为子空间，比星型模式更具规范化，但常用的还是星型模式。数据仓库表通常都很宽，事实表通常都超过100列。
<br>

## 列式存储

1. 如果事实表中有数以万亿行、PB大小的数据，则高效地存储和查询这些数据将成为一个具有挑战性的问题。而维度表通常只有数百万行，数据仓库将主要关注事实表的存储。
2. 虽然事实表通常超过100列，但典型数据仓库查询往往一次只访问其中4~5列。面向行的存储引擎需要将所有行，即100 个属性组成的行从磁盘加载到内存中、解析并过滤出不符合所需条件的行。除非每次查询都能覆盖索引。
3. 面向列存储的思想是不要将一行中的所有值存储在一起，而是将每列中的所有值存储在一起。如果每个列存储在一个单独的文件中，查询只需要读取和解析使用的列。面向列的存储布局依赖一组列文件，每个文件以相同顺序保存着数据行。因此，如果需要重新组装整行，可以从每个单独的列文件中获取第23个条目，并将它们放在一起构成表的第23行。
<br>

## 列压缩

1. 面向列的存储非常适合压缩，压缩技术取决于列中具体数据模式，在数据仓库中特别有效的一种技术是**位图编码**。
2. 通常，**列中的不同值的数量小于行数**。假设列中有n个不同值，将其转换为n个单独的位图。位图中每一位对应一行。如果行具有该值，该位为1，否则为0。这些位图索引非常适合在数据仓库中常见的查询。
3. 如果n非常小，则这些位图由每行一位存储。如果n较大，在大多数位图中将会有很多零。此时，位图也可以进行**游程编码**，这样列的编码非常紧凑。
<img src="https://gitee.com/jia_hope/markdown-img/raw/master/img/20230301215616.png">
<br>


## 内存带宽和矢量化处理

1. **对于需要扫描数百万行的数据仓库查询，将数据从磁盘加载到内存的带宽是一大瓶颈**。
2. **分析数据库的开发人员还要关心如何高效地将内存的带宽用于CPU缓存，**避免分支错误预测和CPU指令处理流水线中的气泡，并利用现代CPU中的单指令多数据 (SIMD) 指令。
3. **除了减少需要从磁盘加载的数据量之外，面向列的存储布局也有利于高效利用CPU周期**。例如查询引擎可以将一大块压缩列数据放入CPU的L1缓存中，并以紧凑循环(即没有函数调用)进行迭代。CPU能够比基于很多函数调用和条件判断的代码更快地执行这种循环。列压缩使得列中更多的行可以加载到L1缓存。如按位AND和OR的运算符，可被设计成直接对这样的列压缩数据块进行操作。这种技术被称为矢量化处理。
<br>

## 列存储中的排序

1. 在列存储中，行的存储顺序并不太重要。最简单的是按插入顺序保存，这样插入一个新行只是追加到每个列文件。也可以选择强制某个顺序，像SSTable一样，并将其用作索引机制。
2. **单独排序每列是没有意义的**，这样的话就无法知道列中的某一项属于哪一行。相反，**即使数据是按列存储的，它也需要一次排序整行**。可以基于常见查询来选择要排序表的列。
3. 排序还可以帮助进一步压缩列。排序列后更容易进行游程编码。
4. 考虑到不同的查询会从不同的排序中获益，由于数据需要复制到多台机器避免单机故障，可以存储不同方式排序的冗余数据，以便在处理查询时选择最适合特定查询模式的排序版本。
<br>

## 列存储的写操作

1. OLAP大多数负载由分析人员运行的大型只读查询组成。面向列的存储、压缩和排序都非常有助于加速读取查询。但是，它们的缺点是让写入更加困难。
2. **像B-tree使用的原地更新方式，对于压缩的列是不可能的**。**如果在排序表的中间插入一行，那么很可能不得不重写所有的列文件**。
3. **一个很好的解决方案是LSM-Tree。所有的写入首先进入内存存储区，将其添加到已排序的结构中，接着再准备写入磁盘**。执行查询时需要检查磁盘上的列数据和内存中最近的写入，并结合这两者。而查询优化器可以对用户隐藏这些内部细节。从数据分析师的角度来看，插入、更新或删除数据可以立即反映在随后的查询中。
<br>

## 聚合：数据立方体与物化视图

1. 数据仓库还有一个特征是**物化聚合**。数据仓库查询通常涉及聚合函数，则可以事先缓存一些常用的计数或总和等信息。创建这种缓存的一种方式是物化视图。
2. 在关系数据模型中，它通常被定义为虚拟视图，用于编写查询的快捷方式。从虚拟视图中读取时，SOL引擎将其动态地扩展到视图的底层查询，然后处理扩展查询。而物化视图是查询结果的实际副本，并被写到磁盘。当底层数据发生变化时，物化视图也需要随之更新。但这种更新方式会影响数据写入性能，对于大量读密集的数据仓库，物化视图则更有意义。
3. 物化视图常见的一种特殊情况称为数据立方体或OLAP立方体，它是由不同维度分组的聚合网格。
<img src="https://gitee.com/jia_hope/markdown-img/raw/master/img/20230301230030.png">
4. 物化数据立方体的优点是某些查询会非常快，主要是它们已被预先计算出来。缺点是缺乏像查询原始数据那样的灵活性。例如没有办法直接计算成本超过100美元的物品所占销售的比重。因此大多数据仓库都保留尽可能多的原始数据，仅当数据立方体可以对特定查询显著提升性能时，才会采用多维数据聚合。
<br>

## OLAP和OLTP总结

1. OLTP系统通常面向用户，这意味着它们可能收到大量的请求。为了处理负载应用程序通常在每个查询中只涉及少量的记录。应用程序基于某种键来请求记录，而存储引擎使用索引来查找所请求键的数据。磁盘寻道时间往往是瓶颈。
2. OLAP主要由业务分析师使用。处理的查询请求数目远低于OLTP系统，但每个查询通常要求非常苛刻，需要在短时间内扫描数百万条记录。磁盘带宽通常是瓶颈，而面向列的存储对于这种工作负载成为日益流行的解决方案。
3. 当查询需要在大量行中顺序扫描时，索引的关联性就会显著降低。相反，最重要的是非常紧凑地编码数据，以尽量减少磁盘读取的数据量。而列存储可以帮助实现这目标。
4. 在OLTP方面有两个主要流派的存储引擎：
	* **日志结构流派：**只允许追加式更新文件和删除过时的文件，但不会修改已写入的文件。如SSTables、LSM-tree、Lucene等。日志结构的存储引擎关键思想是系统地将磁盘上随机访问写入转为顺序写入，由于硬盘驱动器和SSD 的性能特性，可以实现更高的写入吞吐量。
	* **原地更新流派：**将磁盘视为可以覆盖的一组固定大小的页，如B-tree。